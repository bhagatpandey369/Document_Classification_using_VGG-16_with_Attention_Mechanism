{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2323bd1-76e5-4b28-94b3-4e2fc55161b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import ToTensor\n",
    "# from network import AttnVGG\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f3a234-d3a0-48fb-8b8d-cfd0f9a85f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/rishab/alexnet_attention/train\"\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset = datasets.ImageFolder(root=root_dir,transform=transform)\n",
    "\n",
    "train_size = 0.8 \n",
    "train_data, val_data = train_test_split(dataset, train_size=train_size, shuffle=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d762fe-cf7b-478a-90c9-17ccba79e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def compute_metrics(all_labels,all_preds,num_classes,epoch):\n",
    "    CM = confusion_matrix(all_labels, all_preds, labels=list(range(16)))\n",
    "    acc = np.sum(np.diag(CM)) / np.sum(CM)\n",
    "    \n",
    "    class_sensitivity = []\n",
    "    class_precision = []\n",
    "    class_metrics = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        tp = CM[class_idx, class_idx]\n",
    "        fn = np.sum(CM[class_idx, :]) - tp\n",
    "        fp = np.sum(CM[:, class_idx]) - tp\n",
    "        tn = np.sum(CM) - tp - fn - fp\n",
    "        \n",
    "        sensitivity = tp / (tp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        class_sensitivity.append(sensitivity)\n",
    "        class_precision.append(precision)\n",
    "        class_metrics.append([sensitivity, precision])\n",
    "        \n",
    "    val_mean_sensitivity = np.mean(class_sensitivity)\n",
    "    val_mean_precision = np.mean(class_precision)\n",
    "    return acc,val_mean_sensitivity,val_mean_precision,CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b254d71d-c14c-46d0-acb9-1352477d5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3d085c-d168-4429-ba1c-ff1afa5897e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16_bn(weights=torchvision.models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "\n",
    "num_classes = 16\n",
    "model.classifier[6] = torch.nn.Linear(4096, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8425e20b-15f8-4434-a7b1-bfeb8f2ff696",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "lr_lambda = lambda epoch : np.power(0.1, epoch//10)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da4c22a-d991-4ab0-84cd-faf6ffbe75b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Traning Loss: 2.0221, Validation Loss:  1.8698, Validation Accuracy,48.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3244/1507601269.py:16: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sensitivity = tp / (tp + fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Traning Loss: 1.3614, Validation Loss:  1.1543, Validation Accuracy,65.61%\n",
      "Epoch [3/30], Traning Loss: 1.0898, Validation Loss:  1.0380, Validation Accuracy,68.87%\n",
      "Epoch [4/30], Traning Loss: 0.8727, Validation Loss:  0.9647, Validation Accuracy,69.52%\n",
      "Epoch [5/30], Traning Loss: 0.7468, Validation Loss:  0.8847, Validation Accuracy,74.27%\n",
      "Epoch [6/30], Traning Loss: 0.6091, Validation Loss:  0.8848, Validation Accuracy,74.19%\n",
      "Epoch [7/30], Traning Loss: 0.5147, Validation Loss:  0.8346, Validation Accuracy,75.23%\n",
      "Epoch [8/30], Traning Loss: 0.4546, Validation Loss:  0.8533, Validation Accuracy,76.53%\n",
      "Epoch [9/30], Traning Loss: 0.3765, Validation Loss:  0.9789, Validation Accuracy,75.15%\n",
      "Epoch [10/30], Traning Loss: 0.3756, Validation Loss:  0.9474, Validation Accuracy,75.84%\n",
      "Epoch [11/30], Traning Loss: 0.1507, Validation Loss:  0.8355, Validation Accuracy,79.37%\n",
      "Epoch [12/30], Traning Loss: 0.0983, Validation Loss:  0.8554, Validation Accuracy,78.91%\n",
      "Epoch [13/30], Traning Loss: 0.0738, Validation Loss:  0.9140, Validation Accuracy,78.91%\n",
      "Epoch [14/30], Traning Loss: 0.0620, Validation Loss:  0.9362, Validation Accuracy,79.06%\n",
      "Epoch [15/30], Traning Loss: 0.0534, Validation Loss:  0.9588, Validation Accuracy,79.49%\n",
      "Epoch [16/30], Traning Loss: 0.0437, Validation Loss:  1.0072, Validation Accuracy,79.37%\n",
      "Epoch [17/30], Traning Loss: 0.0394, Validation Loss:  1.0037, Validation Accuracy,79.83%\n",
      "Epoch [18/30], Traning Loss: 0.0315, Validation Loss:  1.0695, Validation Accuracy,79.60%\n",
      "Epoch [19/30], Traning Loss: 0.0284, Validation Loss:  1.0773, Validation Accuracy,79.98%\n",
      "Epoch [20/30], Traning Loss: 0.0279, Validation Loss:  1.1214, Validation Accuracy,80.06%\n",
      "Epoch [21/30], Traning Loss: 0.0196, Validation Loss:  1.1251, Validation Accuracy,79.68%\n",
      "Epoch [22/30], Traning Loss: 0.0189, Validation Loss:  1.1283, Validation Accuracy,79.95%\n",
      "Epoch [23/30], Traning Loss: 0.0183, Validation Loss:  1.1325, Validation Accuracy,79.98%\n",
      "Epoch [24/30], Traning Loss: 0.0151, Validation Loss:  1.1404, Validation Accuracy,79.87%\n",
      "Epoch [25/30], Traning Loss: 0.0186, Validation Loss:  1.1440, Validation Accuracy,80.02%\n",
      "Epoch [26/30], Traning Loss: 0.0181, Validation Loss:  1.1368, Validation Accuracy,79.64%\n",
      "Epoch [27/30], Traning Loss: 0.0181, Validation Loss:  1.1385, Validation Accuracy,80.02%\n",
      "Epoch [28/30], Traning Loss: 0.0162, Validation Loss:  1.1527, Validation Accuracy,80.02%\n",
      "Epoch [29/30], Traning Loss: 0.0157, Validation Loss:  1.1383, Validation Accuracy,79.91%\n",
      "Epoch [30/30], Traning Loss: 0.0164, Validation Loss:  1.1420, Validation Accuracy,79.87%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"logs_vgg16\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    writer.add_scalar(\"Training Loss\" , avg_train_loss,epoch)\n",
    "\n",
    "    # Adjusting Learning Rate\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "          inputs = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs,labels)\n",
    "          val_loss += loss.item()*images.size(0)\n",
    "          _,predict = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predict == labels).sum().item()\n",
    "          all_preds.extend(predict.cpu().numpy())\n",
    "          all_labels.extend(labels.cpu().numpy())\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    accuracy_val = 100*correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Traning Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss: .4f}, Validation Accuracy,{accuracy_val:.2f}%')\n",
    "    \n",
    "    acc,val_mean_sensitivity,val_mean_precision,CM = compute_metrics(all_preds,all_labels,num_classes=16,epoch=epoch)\n",
    "    writer.add_scalar('val/accuracy', acc*100, epoch)\n",
    "    writer.add_scalar('val/mean_recall', val_mean_sensitivity,epoch)\n",
    "    writer.add_scalar('val/precision_mel',val_mean_precision, epoch)\n",
    "    writer.add_scalar(\"Validation Loss\",val_loss,epoch)\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    sns.heatmap(CM, annot=True, cmap=\"coolwarm\")\n",
    "\n",
    "    # Add the figure to the SummaryWriter\n",
    "    writer.add_figure(\"heatmap\", fig,global_step=epoch)\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "      best_val_loss = val_loss\n",
    "      checkpoint_path = '/home/rishab/alexnet_attention/saved_model_1_vgg16'\n",
    "      os.makedirs(checkpoint_path, exist_ok=True)\n",
    "      checkpoint_path = os.path.join(checkpoint_path ,'best_model.pth')\n",
    "      torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "  \n",
    "    if epoch == num_epochs - 1:\n",
    "        checkpoint_path = '/home/rishab/alexnet_attention/last_epoch_model_vgg16'\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(checkpoint_path ,'last_model.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "   \n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd21a6-5821-466f-af31-ce32d77207ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
